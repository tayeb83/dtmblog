---
layout: post
title:  "تلخيص مستفيض ومبسّط لورقة «Knowledge Graph-extended Retrieval-Augmented Generation for Question Answering»"
date:   2025-07-28
tags:   KG LLM RAG Question-Answering MetaQA
lang:   ar
---

> **تنويه**  
> يُقدَّم هذا التلخيص باللغة العربية الفصحى وبأسلوب تدريسي ميسّر مع تقسيمات واضحة، حتى يسهل إدراجه مباشرةً في مدوّنة Jekyll. يمكنك تعديل الواجهة الأماميّة (Front-Matter) أو ترويسة Markdown كما يلائمك.

---

## 1. مقدّمة عامّة
تتزايد الحاجة إلى أنظمة قادرة على **طرح الأسئلة والجواب عليها** بدقّة ووضوح وقابلية تفسير، في ظلّ النمو الهائل للبيانات الرقمية.  
- **نماذج اللغة الضخمة (LLMs)** مثل ChatGPT تتميّز بفهم اللغة الطبيعية والتعلّم من أمثلة قليلة ولكن تُعاني _هلوسة_ ونقص معرفة ما بعد تاريخ التدريب.  
- **رسوم المعرفة (KGs)** تخزّن الحقائق في شكل ثلاثيات (موضوع، علاقة، كائن) وتَعطي إجابات دقيقة، لكنها تفتقر إلى الحوار الطبيعيّ.  
- **النظم الهجينة** التي تدمج LLM مع KG—خصوصًا عبر **استرجاع-مدعوم بالتوليد (RAG)**— تعدّ واعدة لكسب ميزات الاثنين.

تهدف الورقة إلى تقديم نظام **KG-RAG** الذي:  
1. لا يتطلّب تدريبًا أو ضبطًا (fine-tuning) على الرسم المعرفي.  
2. يفسّر خطواته من خلال تفكيك السؤال وسلسلة تفكير (Chain-of-Thought).  
3. يرفع دقّة الأسئلة متعدّدة القفزات (multi-hop) على معيار MetaQA.

---

## 2. خلفيّة نظريّة

### 2.1 رسوم المعرفة
- تخزّن معرفتها كثلاثيات بسيطة تمكّن من الاستنتاج الرمزي.
- يسهل استعلامها لكن بناءها مكلف وغير قابل للتعميم التلقائي على مجالات جديدة.

### 2.2 نماذج اللغة الضخمة
- مبنيّة على معماريّة **Transformer** (Vaswani et al. 2017).  
- تُولّد نصًا ذاتيًا، لكنها قد تُهلوس أو تنسى حقائق.

### 2.3 الاسترجاع-مدعوم بالتوليد (RAG)
- يُخزّن نصوصًا مُجزّأة في قاعدة متّجهات؛ يسترجع المقاطع الأقرب ويزوِّد LLM بها لتوليد الجواب.  
- المشكلة: النص غير المُنظَّم قد يحتوي معلومات ناقصة أو مضلِّلة—لذا يُقترح إدراج KG بدل نص حرّ.

---

## 3. مساهمات الورقة

| المساهمة | الوصف |
|----------|-------|
| **KG-RAG بلا تدريب** | يعتمد على استرجاع تشابهي بالنقطة المركزية (dot-product) دون أي ضبط على KG. |
| **وحدة تفكيك السؤال** | تقسّم السؤال المعقّد إلى أسئلة فرعية وتعطي سلسلة تفكير صريحة. |
| **تجارب موسّعة على MetaQA** | تُظهر رفع الدقة في أسئلة 2-hop و3-hop مع خسارة طفيفة في 1-hop. |
| **توازن التفسير والعمومية** | يجمع ميزة KAPING في العمومية وميزة Keqing في الشرح. |

---

## 4. منهجية النظام

1. **تفكيك السؤال**:  
   - يُستخدم نموذج Mistral-7B (كمّي 4-bit) مع أمثلة In-Context.  
   - يُقرر إذا كان التفكيك لازمًا، ثم يَخرج بسلسلة تفكير وأسئلة فرعية.

2. **استرجاع ثلاثيات المرشّحة**:  
   - بحث عَرضي (Breadth-First) حتى `N` قفزات حول كيان السؤال.  
   - تُلفظ الثلاثية نصيًا (subject, relation, object).

3. **إجابة الأسئلة الفرعية**:  
   - تمثيل بمتّجهات (Sentence-Transformer `multi-qa-mpnet-base-dot-v1`).  
   - اختيار أعلى `K` ثلاثيات تشابهًا، ثم تمريرها لـ LLM لإنتاج الجواب الفرعي.  
   - يُعاد صياغة السؤال التالي اعتمادًا على الجواب السابق.

4. **تركيب الجواب النهائي**:  
   - LLM يدمج سلسلة التفكير والأسئلة الفرعية وأجوبتها لصياغة جواب نهائي مُبرّر.

---

## 5. التجارب والنتائج

### 5.1 إعداد التجربة
- معيار **MetaQA**: ثلاث مجموعات (1-hop، 2-hop، 3-hop)، كل واحدة ≈ 100k سؤال.  
- أُخذت عيّنات مقيدة (100 / 500 سؤال) لأسباب حسابية.  
- قياس الأداء: **Hit@1** (تطابق الجواب مع أي كيان صحيح).

### 5.2 اختيار المعاملات
- دراسة قيم `N∈{1,2,3}` و `K∈{10,20,30}`.  
- أفضل توازن = **`N=3`, `K=30`** للحصول على أداء مستقر لكل المجموعات.

### 5.3 مقارنة خطوط أساس
| المجموعة | LLM فقط | LLM + KG (KAPING) | LLM + QD | **KG-RAG (المقترح)** |
|-----------|---------|-------------------|----------|-----------------------|
| 1-hop | **0.93** | 0.92 | 0.90 | 0.91 |
| 2-hop | 0.40 | 0.78 | 0.55 | **0.82** |
| 3-hop | 0.15 | 0.55 | 0.32 | **0.58** |

> يلاحظ تفوّق KG-RAG في الأسئلة متعدّدة القفزات مع تضحية طفيفة في الأسئلة البسيطة.

---

## 6. تحليل نوعي (Qualitative)

- **تفكيك زائد**: أحيانًا يجزّئ سؤالًا بسيطًا بلا حاجة → إجابات مطوّلة.  
- **تفكيك ناقص**: لبعض 3-hop لا يُنشئ إلا سؤالَيْن فرعيَيْن.  
- **توليد أجوبة فرعية غير مطابقة**: يَغفل عن ثلاثية صحيحة أو يُدخل معرفة خارجية.  
- **تركيب نهائي مسهب**: قد يتجاوز حدود الرموز أو يضيف تفاصيل غير مطلوبة.

رغم ذلك تبقى **سلسلة التفكير منطقية**، ما يسمح للمستخدم بتتبّع الخطوات والتحقّق.

---

## 7. القيود

1. **حجم النموذج**: استخدام إصدار كمّي صغير يقلّل الأداء المطلق.  
2. **قياس Hit@1**: غير مثالي للأسئلة المقارنة أو الإجابات متعددة الكيانات.  
3. **بساطة MetaQA**: بعض أسئلة 3-hop تُحلّ بـ 1-hop فعلًا، ما قد يحابي الطرق الأبسط.

---

## 8. الخلاصة

- **KG-RAG بلا تدريب** يحقّق توازنًا رائدًا بين الدقّة وقابلية التفسير.  
- **تفكيك السؤال** يُحسّن الاسترجاع والتفسير، وخاصة في الأسئلة المعقّدة.  
- التوجّه المستقبلي يشمل:  
  1. بنى معرفية غنيّة باللغة الطبيعيّة (Mintaka، Wikidata).  
  2. مقاييس تقويم آلية — كالتطابق الدلالي وسلامة سلسلة التفكير.  
  3. تحسين LLM أو استخدام نماذج أكبر مع ضبط أفضل لمعلمات التوليد.

---

## 9. كلمات مفتاحية
رسوم المعرفة، نماذج اللغة الضخمة، استرجاع-مدعوم بالتوليد، سؤال-جواب، MetaQA، تفكيك السؤال، سلسلة التفكير.

---
